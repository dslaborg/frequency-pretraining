[2024-10-01 18:25:49,595][INFO][fine-tune:25] - Using GPU 4
[2024-10-01 18:25:49,597][INFO][fine-tune:35] - overrides:
hydra:
- hydra.launcher.n_jobs=20
- hydra.mode=MULTIRUN
task:
- m_seed_path_sids={seeds:[1,1,1,1,1],path:"exp003b-m1-simple_multi_class-2024-09-17_19-35-00-final.pth",subject_ids:{isruc:$\{data.isruc.cv_5_fold.fold_2\}}}
- data.downstream.train_dataloader.dataset.data_reducer.n_subjects=-1
- general.gpus=[3,4,5]

[2024-10-01 18:25:54,347][INFO][data_loaders:39] - class distribution before data reduction:
# samples per subject
sg1-1-1: 880
sg1-10-1: 842
sg1-11-1: 997
sg1-12-1: 850
sg1-13-1: 882
sg1-14-1: 906
sg1-16-1: 883
sg1-17-1: 851
sg1-19-1: 828
sg1-20-1: 950
sg1-22-1: 849
sg1-23-1: 892
sg1-26-1: 1062
sg1-28-1: 882
sg1-29-1: 912
sg1-3-1: 943
sg1-31-1: 877
sg1-32-1: 1010
sg1-33-1: 920
sg1-34-1: 871
sg1-35-1: 788
sg1-36-1: 987
sg1-37-1: 806
sg1-38-1: 932
sg1-39-1: 900
sg1-40-1: 875
sg1-42-1: 812
sg1-43-1: 747
sg1-44-1: 932
sg1-45-1: 906
sg1-46-1: 863
sg1-48-1: 981
sg1-49-1: 793
sg1-5-1: 875
sg1-50-1: 905
sg1-51-1: 856
sg1-52-1: 912
sg1-53-1: 910
sg1-54-1: 814
sg1-59-1: 942
sg1-6-1: 897
sg1-61-1: 852
sg1-62-1: 864
sg1-63-1: 954
sg1-64-1: 892
sg1-65-1: 1014
sg1-66-1: 845
sg1-67-1: 862
sg1-68-1: 956
sg1-69-1: 815
sg1-71-1: 829
sg1-72-1: 872
sg1-74-1: 897
sg1-76-1: 850
sg1-77-1: 805
sg1-78-1: 894
sg1-80-1: 889
sg1-81-1: 911
sg1-83-1: 925
sg1-84-1: 963
sg1-85-1: 896
sg1-86-1: 964
sg1-88-1: 1002
sg1-9-1: 969
sg1-90-1: 933
sg1-91-1: 990
sg1-92-1: 877
sg1-95-1: 865
sg1-97-1: 912
sg1-99-1: 835
sg2-1-1: 933
sg2-1-2: 787
sg2-3-1: 871
sg2-3-2: 813
sg2-4-1: 932
sg2-4-2: 899
sg2-6-1: 965
sg2-6-2: 1014
sg2-7-1: 942
sg2-7-2: 899
sg2-8-1: 815
sg2-8-2: 923
sg3-10-1: 796
sg3-2-1: 941
sg3-3-1: 824
sg3-4-1: 794
sg3-6-1: 853
sg3-7-1: 814
sg3-8-1: 1000
sg3-9-1: 969

# samples per stage
0: 18096
1: 10902
2: 25149
3: 15812
4: 10477
[2024-10-01 18:25:54,513][INFO][data_loaders:43] - class distribution after data reduction:
# samples per subject
sg1-1-1: 880
sg1-10-1: 842
sg1-11-1: 997
sg1-12-1: 850
sg1-13-1: 882
sg1-14-1: 906
sg1-16-1: 883
sg1-17-1: 851
sg1-19-1: 828
sg1-20-1: 950
sg1-22-1: 849
sg1-23-1: 892
sg1-26-1: 1062
sg1-28-1: 882
sg1-29-1: 912
sg1-3-1: 943
sg1-31-1: 877
sg1-32-1: 1010
sg1-33-1: 920
sg1-34-1: 871
sg1-35-1: 788
sg1-36-1: 987
sg1-37-1: 806
sg1-38-1: 932
sg1-39-1: 900
sg1-40-1: 875
sg1-42-1: 812
sg1-43-1: 747
sg1-44-1: 932
sg1-45-1: 906
sg1-46-1: 863
sg1-48-1: 981
sg1-49-1: 793
sg1-5-1: 875
sg1-50-1: 905
sg1-51-1: 856
sg1-52-1: 912
sg1-53-1: 910
sg1-54-1: 814
sg1-59-1: 942
sg1-6-1: 897
sg1-61-1: 852
sg1-62-1: 864
sg1-63-1: 954
sg1-64-1: 892
sg1-65-1: 1014
sg1-66-1: 845
sg1-67-1: 862
sg1-68-1: 956
sg1-69-1: 815
sg1-71-1: 829
sg1-72-1: 872
sg1-74-1: 897
sg1-76-1: 850
sg1-77-1: 805
sg1-78-1: 894
sg1-80-1: 889
sg1-81-1: 911
sg1-83-1: 925
sg1-84-1: 963
sg1-85-1: 896
sg1-86-1: 964
sg1-88-1: 1002
sg1-9-1: 969
sg1-90-1: 933
sg1-91-1: 990
sg1-92-1: 877
sg1-95-1: 865
sg1-97-1: 912
sg1-99-1: 835
sg2-1-1: 933
sg2-1-2: 787
sg2-3-1: 871
sg2-3-2: 813
sg2-4-1: 932
sg2-4-2: 899
sg2-6-1: 965
sg2-6-2: 1014
sg2-7-1: 942
sg2-7-2: 899
sg2-8-1: 815
sg2-8-2: 923
sg3-10-1: 796
sg3-2-1: 941
sg3-3-1: 824
sg3-4-1: 794
sg3-6-1: 853
sg3-7-1: 814
sg3-8-1: 1000
sg3-9-1: 969

# samples per stage
0: 18096
1: 10902
2: 25149
3: 15812
4: 10477
[2024-10-01 18:25:54,534][INFO][base_pretraining_fe:55] - Loading model from exp003b-m1-simple_multi_class-2024-09-17_19-35-00-final.pth
[2024-10-01 18:25:56,399][INFO][data_loaders:39] - class distribution before data reduction:
# samples per subject
sg1-21-1: 1054
sg1-24-1: 830
sg1-30-1: 882
sg1-4-1: 963
sg1-55-1: 879
sg1-57-1: 1007
sg1-70-1: 893
sg1-87-1: 926

# samples per stage
0: 1560
1: 831
2: 2431
3: 1417
4: 1195
[2024-10-01 18:25:56,407][INFO][data_loaders:43] - class distribution after data reduction:
# samples per subject
sg1-21-1: 1054
sg1-24-1: 830
sg1-30-1: 882
sg1-4-1: 963
sg1-55-1: 879
sg1-57-1: 1007
sg1-70-1: 893
sg1-87-1: 926

# samples per stage
0: 1560
1: 831
2: 2431
3: 1417
4: 1195
[2024-10-01 18:25:57,247][INFO][clas_trainer:49] - metrics before training (epoch 0):
[2024-10-01 18:26:13,128][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.2132
[2024-10-01 18:26:29,160][INFO][clas_trainer:133] - train epoch: 1 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 1.682314
[2024-10-01 18:26:44,607][INFO][clas_trainer:133] - train epoch: 1 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 1.139424
[2024-10-01 18:26:59,741][INFO][clas_trainer:133] - train epoch: 1 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.920451
[2024-10-01 18:27:14,915][INFO][clas_trainer:133] - train epoch: 1 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.919069
[2024-10-01 18:27:30,278][INFO][clas_trainer:133] - train epoch: 1 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 1.131612
[2024-10-01 18:27:45,623][INFO][clas_trainer:133] - train epoch: 1 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.502572
[2024-10-01 18:28:00,555][INFO][clas_trainer:133] - train epoch: 1 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.893018
[2024-10-01 18:28:15,576][INFO][clas_trainer:133] - train epoch: 1 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.620615
[2024-10-01 18:28:30,553][INFO][clas_trainer:133] - train epoch: 1 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.802519
[2024-10-01 18:28:45,501][INFO][clas_trainer:133] - train epoch: 1 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.764187
[2024-10-01 18:29:01,990][INFO][clas_trainer:63] - [epoch   1] execution time: 168.86s	metrics:
[2024-10-01 18:29:01,990][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7226
[2024-10-01 18:29:02,011][INFO][base_model:51] - snapshot saved to XXX/frequency-pretraining/models/exp003b-m1-base_fe_clas-2024-10-01_18-25-45-final.pth
[2024-10-01 18:29:17,150][INFO][clas_trainer:133] - train epoch: 2 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.714963
[2024-10-01 18:29:31,784][INFO][clas_trainer:133] - train epoch: 2 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.579102
[2024-10-01 18:29:46,261][INFO][clas_trainer:133] - train epoch: 2 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.732091
[2024-10-01 18:30:00,907][INFO][clas_trainer:133] - train epoch: 2 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.946368
[2024-10-01 18:30:15,436][INFO][clas_trainer:133] - train epoch: 2 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.863393
[2024-10-01 18:30:30,194][INFO][clas_trainer:133] - train epoch: 2 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.809421
[2024-10-01 18:30:45,308][INFO][clas_trainer:133] - train epoch: 2 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.607774
[2024-10-01 18:31:00,384][INFO][clas_trainer:133] - train epoch: 2 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.501777
[2024-10-01 18:31:15,075][INFO][clas_trainer:133] - train epoch: 2 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.544248
[2024-10-01 18:31:29,794][INFO][clas_trainer:133] - train epoch: 2 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.807119
[2024-10-01 18:31:47,494][INFO][clas_trainer:63] - [epoch   2] execution time: 165.48s	metrics:
[2024-10-01 18:31:47,494][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7396
[2024-10-01 18:31:47,517][INFO][base_model:51] - snapshot saved to XXX/frequency-pretraining/models/exp003b-m1-base_fe_clas-2024-10-01_18-25-45-final.pth
[2024-10-01 18:32:02,958][INFO][clas_trainer:133] - train epoch: 3 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.804135
[2024-10-01 18:32:18,116][INFO][clas_trainer:133] - train epoch: 3 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.762654
[2024-10-01 18:32:33,412][INFO][clas_trainer:133] - train epoch: 3 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.388114
[2024-10-01 18:32:49,004][INFO][clas_trainer:133] - train epoch: 3 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.503845
[2024-10-01 18:33:04,020][INFO][clas_trainer:133] - train epoch: 3 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.474189
[2024-10-01 18:33:19,453][INFO][clas_trainer:133] - train epoch: 3 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.660670
[2024-10-01 18:33:34,541][INFO][clas_trainer:133] - train epoch: 3 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.601325
[2024-10-01 18:33:49,489][INFO][clas_trainer:133] - train epoch: 3 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.454540
[2024-10-01 18:34:04,825][INFO][clas_trainer:133] - train epoch: 3 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.395667
[2024-10-01 18:34:19,903][INFO][clas_trainer:133] - train epoch: 3 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.665940
[2024-10-01 18:34:37,349][INFO][clas_trainer:63] - [epoch   3] execution time: 169.83s	metrics:
[2024-10-01 18:34:37,350][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7574
[2024-10-01 18:34:37,372][INFO][base_model:51] - snapshot saved to XXX/frequency-pretraining/models/exp003b-m1-base_fe_clas-2024-10-01_18-25-45-final.pth
[2024-10-01 18:34:52,712][INFO][clas_trainer:133] - train epoch: 4 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.611719
[2024-10-01 18:35:07,414][INFO][clas_trainer:133] - train epoch: 4 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.650938
[2024-10-01 18:35:22,352][INFO][clas_trainer:133] - train epoch: 4 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.663786
[2024-10-01 18:35:37,227][INFO][clas_trainer:133] - train epoch: 4 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.804218
[2024-10-01 18:35:52,106][INFO][clas_trainer:133] - train epoch: 4 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.820575
[2024-10-01 18:36:06,662][INFO][clas_trainer:133] - train epoch: 4 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.390121
[2024-10-01 18:36:21,470][INFO][clas_trainer:133] - train epoch: 4 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.507700
[2024-10-01 18:36:36,267][INFO][clas_trainer:133] - train epoch: 4 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.687926
[2024-10-01 18:36:51,063][INFO][clas_trainer:133] - train epoch: 4 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.585625
[2024-10-01 18:37:05,666][INFO][clas_trainer:133] - train epoch: 4 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.682946
[2024-10-01 18:37:22,844][INFO][clas_trainer:63] - [epoch   4] execution time: 165.47s	metrics:
[2024-10-01 18:37:22,844][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7405
[2024-10-01 18:37:38,265][INFO][clas_trainer:133] - train epoch: 5 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.568130
[2024-10-01 18:37:53,193][INFO][clas_trainer:133] - train epoch: 5 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.570876
[2024-10-01 18:38:08,104][INFO][clas_trainer:133] - train epoch: 5 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.514086
[2024-10-01 18:38:23,164][INFO][clas_trainer:133] - train epoch: 5 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.616560
[2024-10-01 18:38:38,200][INFO][clas_trainer:133] - train epoch: 5 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.746463
[2024-10-01 18:38:53,186][INFO][clas_trainer:133] - train epoch: 5 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.800048
[2024-10-01 18:39:08,026][INFO][clas_trainer:133] - train epoch: 5 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.312541
[2024-10-01 18:39:22,959][INFO][clas_trainer:133] - train epoch: 5 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.548999
[2024-10-01 18:39:38,082][INFO][clas_trainer:133] - train epoch: 5 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.377855
[2024-10-01 18:39:52,997][INFO][clas_trainer:133] - train epoch: 5 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.529236
[2024-10-01 18:40:09,767][INFO][clas_trainer:63] - [epoch   5] execution time: 166.92s	metrics:
[2024-10-01 18:40:09,767][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7283
[2024-10-01 18:40:25,361][INFO][clas_trainer:133] - train epoch: 6 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.552090
[2024-10-01 18:40:40,100][INFO][clas_trainer:133] - train epoch: 6 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.583828
[2024-10-01 18:40:54,945][INFO][clas_trainer:133] - train epoch: 6 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.517169
[2024-10-01 18:41:09,870][INFO][clas_trainer:133] - train epoch: 6 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.601602
[2024-10-01 18:41:24,555][INFO][clas_trainer:133] - train epoch: 6 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.800321
[2024-10-01 18:41:39,499][INFO][clas_trainer:133] - train epoch: 6 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.969241
[2024-10-01 18:41:54,365][INFO][clas_trainer:133] - train epoch: 6 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.353336
[2024-10-01 18:42:09,066][INFO][clas_trainer:133] - train epoch: 6 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.676160
[2024-10-01 18:42:24,016][INFO][clas_trainer:133] - train epoch: 6 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.653663
[2024-10-01 18:42:38,878][INFO][clas_trainer:133] - train epoch: 6 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.348518
[2024-10-01 18:42:55,593][INFO][clas_trainer:63] - [epoch   6] execution time: 165.83s	metrics:
[2024-10-01 18:42:55,593][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7545
[2024-10-01 18:43:10,872][INFO][clas_trainer:133] - train epoch: 7 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.696438
[2024-10-01 18:43:25,798][INFO][clas_trainer:133] - train epoch: 7 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.477316
[2024-10-01 18:43:41,223][INFO][clas_trainer:133] - train epoch: 7 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.661690
[2024-10-01 18:43:58,908][INFO][clas_trainer:133] - train epoch: 7 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.609355
[2024-10-01 18:44:17,110][INFO][clas_trainer:133] - train epoch: 7 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.621829
[2024-10-01 18:44:34,921][INFO][clas_trainer:133] - train epoch: 7 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.476570
[2024-10-01 18:44:53,028][INFO][clas_trainer:133] - train epoch: 7 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.739173
[2024-10-01 18:45:10,922][INFO][clas_trainer:133] - train epoch: 7 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.450236
[2024-10-01 18:45:28,637][INFO][clas_trainer:133] - train epoch: 7 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.787924
[2024-10-01 18:45:46,702][INFO][clas_trainer:133] - train epoch: 7 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.452719
[2024-10-01 18:46:07,034][INFO][clas_trainer:63] - [epoch   7] execution time: 191.44s	metrics:
[2024-10-01 18:46:07,035][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7485
[2024-10-01 18:46:26,371][INFO][clas_trainer:133] - train epoch: 8 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.604950
[2024-10-01 18:46:44,523][INFO][clas_trainer:133] - train epoch: 8 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.638136
[2024-10-01 18:47:02,509][INFO][clas_trainer:133] - train epoch: 8 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.368989
[2024-10-01 18:47:20,719][INFO][clas_trainer:133] - train epoch: 8 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.376366
[2024-10-01 18:47:39,313][INFO][clas_trainer:133] - train epoch: 8 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.705052
[2024-10-01 18:47:57,464][INFO][clas_trainer:133] - train epoch: 8 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.671383
[2024-10-01 18:48:15,285][INFO][clas_trainer:133] - train epoch: 8 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.582732
[2024-10-01 18:48:33,250][INFO][clas_trainer:133] - train epoch: 8 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.330308
[2024-10-01 18:48:51,271][INFO][clas_trainer:133] - train epoch: 8 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.650685
[2024-10-01 18:49:09,399][INFO][clas_trainer:133] - train epoch: 8 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.531723
[2024-10-01 18:49:30,025][INFO][clas_trainer:63] - [epoch   8] execution time: 202.99s	metrics:
[2024-10-01 18:49:30,025][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7327
[2024-10-01 18:49:48,635][INFO][clas_trainer:133] - train epoch: 9 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.657039
[2024-10-01 18:50:06,267][INFO][clas_trainer:133] - train epoch: 9 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.526540
[2024-10-01 18:50:24,456][INFO][clas_trainer:133] - train epoch: 9 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.447372
[2024-10-01 18:50:42,666][INFO][clas_trainer:133] - train epoch: 9 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.384696
[2024-10-01 18:51:00,675][INFO][clas_trainer:133] - train epoch: 9 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.435013
[2024-10-01 18:51:19,296][INFO][clas_trainer:133] - train epoch: 9 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.610467
[2024-10-01 18:51:37,874][INFO][clas_trainer:133] - train epoch: 9 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.569878
[2024-10-01 18:51:56,376][INFO][clas_trainer:133] - train epoch: 9 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.445145
[2024-10-01 18:52:14,195][INFO][clas_trainer:133] - train epoch: 9 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.417672
[2024-10-01 18:52:32,182][INFO][clas_trainer:133] - train epoch: 9 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.549839
[2024-10-01 18:52:52,758][INFO][clas_trainer:63] - [epoch   9] execution time: 202.73s	metrics:
[2024-10-01 18:52:52,759][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7530
[2024-10-01 18:53:12,287][INFO][clas_trainer:133] - train epoch: 10 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.486537
[2024-10-01 18:53:30,248][INFO][clas_trainer:133] - train epoch: 10 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.433414
[2024-10-01 18:53:48,988][INFO][clas_trainer:133] - train epoch: 10 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.483804
[2024-10-01 18:54:07,296][INFO][clas_trainer:133] - train epoch: 10 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.362737
[2024-10-01 18:54:26,050][INFO][clas_trainer:133] - train epoch: 10 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.746215
[2024-10-01 18:54:44,397][INFO][clas_trainer:133] - train epoch: 10 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.685811
[2024-10-01 18:55:02,650][INFO][clas_trainer:133] - train epoch: 10 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.696499
[2024-10-01 18:55:20,896][INFO][clas_trainer:133] - train epoch: 10 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.517679
[2024-10-01 18:55:39,666][INFO][clas_trainer:133] - train epoch: 10 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.623127
[2024-10-01 18:55:57,742][INFO][clas_trainer:133] - train epoch: 10 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.369430
[2024-10-01 18:56:17,773][INFO][clas_trainer:63] - [epoch  10] execution time: 205.01s	metrics:
[2024-10-01 18:56:17,773][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7572
[2024-10-01 18:56:36,168][INFO][clas_trainer:133] - train epoch: 11 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.420700
[2024-10-01 18:56:54,396][INFO][clas_trainer:133] - train epoch: 11 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.564035
[2024-10-01 18:57:12,347][INFO][clas_trainer:133] - train epoch: 11 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.506797
[2024-10-01 18:57:31,004][INFO][clas_trainer:133] - train epoch: 11 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.604825
[2024-10-01 18:57:49,582][INFO][clas_trainer:133] - train epoch: 11 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.369737
[2024-10-01 18:58:07,980][INFO][clas_trainer:133] - train epoch: 11 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.326600
[2024-10-01 18:58:26,356][INFO][clas_trainer:133] - train epoch: 11 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.619406
[2024-10-01 18:58:44,913][INFO][clas_trainer:133] - train epoch: 11 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.835047
[2024-10-01 18:59:03,198][INFO][clas_trainer:133] - train epoch: 11 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.166428
[2024-10-01 18:59:21,495][INFO][clas_trainer:133] - train epoch: 11 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.462396
[2024-10-01 18:59:41,926][INFO][clas_trainer:63] - [epoch  11] execution time: 204.15s	metrics:
[2024-10-01 18:59:41,927][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7439
[2024-10-01 19:00:01,481][INFO][clas_trainer:133] - train epoch: 12 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.826844
[2024-10-01 19:00:20,862][INFO][clas_trainer:133] - train epoch: 12 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.467174
[2024-10-01 19:00:38,735][INFO][clas_trainer:133] - train epoch: 12 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.655453
[2024-10-01 19:00:56,936][INFO][clas_trainer:133] - train epoch: 12 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.428792
[2024-10-01 19:01:15,414][INFO][clas_trainer:133] - train epoch: 12 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.571920
[2024-10-01 19:01:33,501][INFO][clas_trainer:133] - train epoch: 12 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.295421
[2024-10-01 19:01:51,257][INFO][clas_trainer:133] - train epoch: 12 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.595769
[2024-10-01 19:02:09,389][INFO][clas_trainer:133] - train epoch: 12 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.441966
[2024-10-01 19:02:27,615][INFO][clas_trainer:133] - train epoch: 12 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.460584
[2024-10-01 19:02:45,578][INFO][clas_trainer:133] - train epoch: 12 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.568970
[2024-10-01 19:03:05,375][INFO][clas_trainer:63] - [epoch  12] execution time: 203.45s	metrics:
[2024-10-01 19:03:05,375][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7558
[2024-10-01 19:03:24,661][INFO][clas_trainer:133] - train epoch: 13 [8000/80436 (10%)], lr: ['1.00e-04'], loss: 0.228932
[2024-10-01 19:03:43,150][INFO][clas_trainer:133] - train epoch: 13 [16032/80436 (20%)], lr: ['1.00e-04'], loss: 0.357567
[2024-10-01 19:04:01,414][INFO][clas_trainer:133] - train epoch: 13 [24064/80436 (30%)], lr: ['1.00e-04'], loss: 0.469140
[2024-10-01 19:04:19,386][INFO][clas_trainer:133] - train epoch: 13 [32096/80436 (40%)], lr: ['1.00e-04'], loss: 0.292540
[2024-10-01 19:04:37,405][INFO][clas_trainer:133] - train epoch: 13 [40128/80436 (50%)], lr: ['1.00e-04'], loss: 0.387852
[2024-10-01 19:04:55,740][INFO][clas_trainer:133] - train epoch: 13 [48160/80436 (60%)], lr: ['1.00e-04'], loss: 0.321857
[2024-10-01 19:05:13,658][INFO][clas_trainer:133] - train epoch: 13 [56192/80436 (70%)], lr: ['1.00e-04'], loss: 0.298285
[2024-10-01 19:05:31,670][INFO][clas_trainer:133] - train epoch: 13 [64224/80436 (80%)], lr: ['1.00e-04'], loss: 0.645075
[2024-10-01 19:05:49,895][INFO][clas_trainer:133] - train epoch: 13 [72256/80436 (90%)], lr: ['1.00e-04'], loss: 0.237163
[2024-10-01 19:06:08,529][INFO][clas_trainer:133] - train epoch: 13 [80288/80436 (100%)], lr: ['1.00e-04'], loss: 0.301215
[2024-10-01 19:06:28,553][INFO][clas_trainer:63] - [epoch  13] execution time: 203.18s	metrics:
[2024-10-01 19:06:28,554][INFO][clas_evaluator:132] - dataset: earlystopping, avg f1-score: 0.7569
[2024-10-01 19:06:28,557][INFO][clas_trainer:79] - finished training
[2024-10-01 19:06:28,557][INFO][clas_trainer:80] - best model on epoch: 3 	f1-score: 0.7574
